{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles) when measured in a straight line.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {country_a} and {country_b}\"\n",
    ")\n",
    "prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat.predict(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Î“ÎµÎ¹Î± ÏƒÎ±Ï‚! Î— Î±Ï€ÏŒÏƒÏ„Î±ÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï Ï„Î¿Ï… ÎœÎµÎ¾Î¹ÎºÎ¿Ï ÎºÎ±Î¹ Ï„Î·Ï‚ Î¤Î±ÏŠÎ»Î¬Î½Î´Î·Ï‚ ÎµÎ¯Î½Î±Î¹ Ï€ÎµÏÎ¯Ï€Î¿Ï… 16.000 Ï‡Î¹Î»Î¹ÏŒÎ¼ÎµÏ„ÏÎ±. Î¤Î¿ ÏŒÎ½Î¿Î¼Î¬ Î¼Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î£Ï‰ÎºÏÎ¬Ï„Î·Ï‚. Î ÏÏ‚ Î¼Ï€Î¿ÏÏ Î½Î± Î²Î¿Î·Î¸Î®ÏƒÏ‰;')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "    (\"ai\", \"Ciao, mi chiamo {name}!\"),\n",
    "    (\"human\", \"What is the distance between {country_a} and {country_b}. Also, what is your name?\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    language=\"Greek\",\n",
    "    name=\"Socrates\",\n",
    "    country_a=\"Mexico\",\n",
    "    country_b=\"Thailand\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(\"Hello,how,are, you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do NOT reply with anything else.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# prompt = template.format_messages(\n",
    "#     max_items=10,\n",
    "#     question=\"What are the colors?\"\n",
    "# )\n",
    "\n",
    "# result = chat.predict_messages(prompt)\n",
    "\n",
    "# p = CommaOutputParser()\n",
    "\n",
    "# p.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pikachu', 'charmander', 'bulbasaur', 'squirtle', 'jigglypuff']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke({\"max_items\": 5, \"question\": \"What are the pokemons?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipes vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\"),\n",
    "    (\"human\", \"{recipe}\")\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"cuisine\": \"indian\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "poet_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international Poet. You create poetry about programming languages. you use only one programming langauage to one poetry\"),\n",
    "    (\"human\", \"I want to make {language} poetry.\"),\n",
    "])\n",
    "\n",
    "poet_chain = poet_prompt | chat\n",
    "\n",
    "poetry_commentator_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a poetry commentator specialized on explaining programming language's poetry.\"),\n",
    "    (\"human\", \"{poetry}\")\n",
    "])\n",
    "\n",
    "poetry_commentator_chain = poetry_commentator_prompt | chat\n",
    "\n",
    "final_chain = {\"poetry\": poet_chain} | poetry_commentator_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"language\": \"python\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Berlin\n",
      "        Language: German\n",
      "        Food: Bratwurst and Sauerkraut\n",
      "        Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\n        Here is what I know:\\n        Capital: Berlin\\n        Language: German\\n        Food: Bratwurst and Sauerkraut\\n        Currency: Euro')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\" : \"What do you know about France?\",\n",
    "        \"answer\" : \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Human: {question}\n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples=examples,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\": \"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        Director: Bong Joon-ho\n",
      "\t\tMain Cast:\n",
      "\t\tKang-ho Song as Kim Ki-taek\n",
      "\t\tSun-kyun Lee as Park Dong-ik\n",
      "\t\tYeo-jeong Jo as Choi Yeon-gyo\n",
      "\t\tBudget: Approximately $11 million\n",
      "\t\tBox Office Gross: Approximately $266.8 million\n",
      "\t\tGenre: Thriller, Drama, Dark Comedy\n",
      "\t\tSynopsis:â€œParasiteâ€ is a South Korean film that revolves around the Kim family, who cunningly infiltrate the wealthy Park family's household by posing as unrelated skilled workers. As their lives become increasingly intertwined, dark secrets and unexpected events unfold, leading to a gripping tale of class struggle and deception."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"\\n        I know this:\\n        Director: Bong Joon-ho\\n\\t\\tMain Cast:\\n\\t\\tKang-ho Song as Kim Ki-taek\\n\\t\\tSun-kyun Lee as Park Dong-ik\\n\\t\\tYeo-jeong Jo as Choi Yeon-gyo\\n\\t\\tBudget: Approximately $11 million\\n\\t\\tBox Office Gross: Approximately $266.8 million\\n\\t\\tGenre: Thriller, Drama, Dark Comedy\\n\\t\\tSynopsis:â€œParasiteâ€ is a South Korean film that revolves around the Kim family, who cunningly infiltrate the wealthy Park family's household by posing as unrelated skilled workers. As their lives become increasingly intertwined, dark secrets and unexpected events unfold, leading to a gripping tale of class struggle and deception.\")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"movie\": \"Mad Max: Fury Road\",\n",
    "        \"answer\": \"\"\"\n",
    "        Main Cast:\n",
    "        Tom Hardy as Max Rockatansky\n",
    "\t    Charlize Theron as Imperator Furiosa\n",
    "\t    Nicholas Hoult as Nux\n",
    "\t    Budget: Approximately $150-185 million\n",
    "\t    Box Office Gross: Approximately $375.6 million\n",
    "\t    Genre: Post-Apocalyptic, Action\n",
    "\t    Synopsis: â€œMad Max: Fury Roadâ€ is set in a post-apocalyptic world where Max, haunted by his past, becomes involved in a struggle led by Furiosa to escape from the tyrannical Immortan Joe. Together, they embark on a high-octane chase across the desert, fighting for survival and freedom.\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"movie\": \"Titanic\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Director: James Cameron\n",
    "\t    Main Cast:\n",
    "\t\tLeonardo DiCaprio as Jack Dawson\n",
    "\t\tKate Winslet as Rose DeWitt Bukater\n",
    "\t\tBilly Zane as Cal Hockley\n",
    "\t\tBudget: Approximately $200 million\n",
    "\t\tBox Office Gross: Approximately $2.202 billion\n",
    "\t\tGenre: Romance, Drama, Disaster\n",
    "\t\tSynopsis:â€œTitanicâ€ is a tragic love story set against the backdrop of the RMS Titanicâ€™s ill-fated maiden voyage in 1912. It follows the romance between Jack, a poor artist, and Rose, a wealthy woman trapped in an unhappy engagement. Their love faces immense challenges as the ship meets its catastrophic fate.\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"movie\": \"Avatar\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Director: James Cameron\n",
    "\t\tMain Cast:\n",
    "\t\tSam Worthington as Jake Sully\n",
    "\t\tZoe Saldana as Neytiri\n",
    "\t\tSigourney Weaver as Grace Augustine\n",
    "\t\tBudget: Approximately $237 million\n",
    "\t\tBox Office Gross: Approximately $2.923 billion\n",
    "\t\tGenre: Sci-Fi, Action, Adventure\n",
    "\t\tSynopsis:â€œAvatarâ€ is set on the lush alien world of Pandora in the 22nd century. The story follows Jake Sully, a paralyzed ex-Marine who participates in the Avatar Program. Through his avatar, Jake immerses himself in the culture of the Naâ€™vi people and eventually leads them in a battle to protect their world from human exploitation.\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"What do you know about {movie}?\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a movie expert, you give short answers.\"),\n",
    "        example_prompt,\n",
    "        (\"human\", \"What do you know about {movie}?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"movie\": \"Parasite\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    \n",
      "    Human:My name is Nico\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Nico! How can I assist you today?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to a human.\n",
    "\n",
    "    {chat_history}\n",
    "    Human:{question}\n",
    "    You:\n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Nico\")\n",
    "\n",
    "chain.predict(question=\"I live in Seoul\")\n",
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    Human: My name is Nico\n",
      "AI: Hello Nico! How can I assist you today?\n",
      "    Human:I live in Seoul\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great to know! How can I assist you with information or tasks related to Seoul?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in Seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    Human: My name is Nico\n",
      "AI: Hello Nico! How can I assist you today?\n",
      "Human: I live in Seoul\n",
      "AI: That's great to know! How can I assist you with information or tasks related to Seoul?\n",
      "    Human:What is my name?\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Nico.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Nice to meet you, Nico! How can I assist you today?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"My name is nico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Your name is Nico.'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"movie\": \"Top Gun\",\n",
    "        \"answer\": \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\",\n",
    "    },\n",
    "    {\n",
    "        \"movie\": \"God Father\",\n",
    "        \"answer\": \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\",\n",
    "    },\n",
    "    {\n",
    "        \"movie\": \"Interstellar\",\n",
    "        \"answer\": \"ğŸš€ğŸŒŒâ³\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{movie}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a movie expert\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        example_prompt,\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ğŸ•°ï¸ğŸ”¥ğŸš—'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"back to the future\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ğŸš¢ğŸ’”ğŸ¶'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"íƒ€ì´íƒ€ë‹‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='back to the future'),\n",
       " AIMessage(content='ğŸ•°ï¸ğŸ”¥ğŸš—'),\n",
       " HumanMessage(content='íƒ€ì´íƒ€ë‹‰'),\n",
       " AIMessage(content='ğŸš¢ğŸ’”ğŸ¶')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_memory(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You asked about the movie \"Back to the Future\"'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What is the movie I asked about earlier?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
